{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('1.21.2', 'cuda')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sea\n",
    "from tqdm.notebook import tqdm\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import cv2\n",
    "import wandb\n",
    "\n",
    "from sklearn.datasets import fetch_openml\n",
    "from scipy.io import loadmat\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "plt.style.use('seaborn')\n",
    "np.__version__, device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9d255659e0c481c89ba9c9cfc2a1665",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ddfdbcec4a14544b45b643c2ba52127",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92e8c90e12dc4afc944be3ace9c7f552",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "((58000, 2), (14000, 2), (18000, 2))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PATH = '/scratch/fk/double_mnist'\n",
    "\n",
    "def load_data(PATH, split):\n",
    "    files, outcome = [], []\n",
    "    \n",
    "    for folder in tqdm(os.listdir(os.path.join(PATH, split))):\n",
    "        if folder[0] == folder[1]:\n",
    "            continue\n",
    "        \n",
    "        for file in os.listdir(os.path.join(PATH, split, folder)):\n",
    "            files.append(os.path.join(PATH, split, folder, file))\n",
    "            outcome.append(folder)\n",
    "            \n",
    "    return pd.DataFrame({\n",
    "        'filename': files,\n",
    "        'outcome': outcome\n",
    "    }).sample(frac=1.0)\n",
    "    \n",
    "df_train = load_data(PATH, 'train')\n",
    "df_val = load_data(PATH, 'val')\n",
    "df_test = load_data(PATH, 'test')\n",
    "\n",
    "df_train.shape, df_val.shape, df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(90000, 2)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.concat([df_train, df_val, df_test], axis=0).sample(frac=1.0)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((72000, 2), (9000, 2), (9000, 2))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "df_train, df_val = train_test_split(df, test_size=0.2, stratify=df['outcome'])\n",
    "df_val, df_test = train_test_split(df_val, test_size=0.5, stratify=df_val['outcome'])\n",
    "\n",
    "df_train.shape, df_val.shape, df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(file):\n",
    "    img = plt.imread(file)\n",
    "    img = cv2.resize(img, (32, 32))\n",
    "    return img\n",
    "\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(0, 1)\n",
    "])\n",
    "\n",
    "class MultiDigitDataset:\n",
    "    def __init__(self, df, transform=None):\n",
    "        self.df = df\n",
    "        self.n_samples = len(df)\n",
    "        self.transform = transform \n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.n_samples\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = load_image(self.df.iloc[idx, 0])\n",
    "        if self.transform:\n",
    "            x = self.transform(x)\n",
    "            \n",
    "        y = self.df.iloc[idx, 1]\n",
    "        y_one_hot = np.zeros(10, dtype=np.float32)\n",
    "        y_one_hot[[int(y[0]), int(y[1])]] = 1\n",
    "        \n",
    "        return x, torch.tensor(y_one_hot)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = MultiDigitDataset(df_train, transform)\n",
    "val_dataset = MultiDigitDataset(df_val, transform)\n",
    "test_dataset = MultiDigitDataset(df_test, transform)\n",
    "\n",
    "batch_size = 256\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([256, 1, 32, 32]), torch.Size([256, 10]))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a, b = next(iter(train_loader))\n",
    "\n",
    "a.shape, b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MlpModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList(\n",
    "            [\n",
    "                self.get_block(1024, 512),\n",
    "                self.get_block(512, 256),\n",
    "                self.get_block(256, 128),\n",
    "                self.get_block(128, 128),\n",
    "                self.get_block(128, 64)\n",
    "                \n",
    "            ]\n",
    "        )\n",
    "        \n",
    "        self.drop = nn.Dropout(0.2)\n",
    "        self.classiifer = nn.Linear(64, 10)\n",
    "    \n",
    "    def get_block(self, in_c, out_c):\n",
    "        return nn.Sequential(\n",
    "            nn.Linear(in_c, out_c, bias=False),\n",
    "            nn.BatchNorm1d(out_c),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2)\n",
    "        )    \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 32*32)\n",
    "        \n",
    "        for i, layer in enumerate(self.layers):\n",
    "            x = layer(x)\n",
    "            \n",
    "        return self.classiifer(x)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "class Trainer:\n",
    "    def __init__(self,\n",
    "                 model,\n",
    "                 train_loader,\n",
    "                 val_loader,\n",
    "                 device,\n",
    "                 loss_fxn, \n",
    "                 logger,\n",
    "                 params):\n",
    "\n",
    "        self.device = device\n",
    "        self.params = params        \n",
    "        self.model = model.to(self.device)\n",
    "        self.train_loader = train_loader\n",
    "        self.val_loader = val_loader\n",
    "        self.loss_fxn = loss_fxn\n",
    "        self.optimizer = torch.optim.Adam(self.model.parameters(), lr = self.params['lr'])\n",
    "        self.logger = logger\n",
    "        \n",
    "    def training_step(self, x, y):\n",
    "        y_pred = self.model(x)\n",
    "        loss = self.loss_fxn(y_pred, y)\n",
    "        y_pred_bin = (y_pred > 0.5).to(torch.int64)\n",
    "        acc = accuracy_score(y_pred_bin.detach().cpu(), y.detach().cpu())\n",
    "        \n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "        \n",
    "        return loss, acc\n",
    "    \n",
    "    def val_step(self, x, y):\n",
    "        with torch.no_grad():\n",
    "            y_pred = self.model(x)\n",
    "            \n",
    "        loss = self.loss_fxn(y_pred, y)\n",
    "        y_pred_bin = (y_pred > 0.5).to(torch.int64)\n",
    "        acc = accuracy_score(y_pred_bin.detach().cpu(), y.detach().cpu())\n",
    "        \n",
    "        return loss, acc\n",
    "    \n",
    "    def go_over_one_batch(self, loader, step_fxn):\n",
    "        loss, acc = 0, 0\n",
    "        for x, y in tqdm(loader):\n",
    "            x, y = x.to(self.device), y.to(self.device)\n",
    "            l, a = step_fxn(x, y)\n",
    "            loss, acc = loss + l, acc + a\n",
    "            \n",
    "        return loss/len(loader), acc/len(loader)\n",
    "    \n",
    "    def train(self, epochs = 10):\n",
    "        for epoch in tqdm(range(epochs)):\n",
    "            \n",
    "            train_loss, train_acc = self.go_over_one_batch(self.train_loader, self.training_step)\n",
    "            val_loss, val_acc = self.go_over_one_batch(self.val_loader, self.val_step)\n",
    "        \n",
    "            print(f\"[Epoch: {epoch}] Training:[loss:{train_loss:.4f} acc:{train_acc:.3f}] Val:[loss:{val_loss:.4f} acc:{val_acc:.3f}]\" )\n",
    "            if self.logger:\n",
    "                self.logger.log({\n",
    "                    'train_loss':train_loss,\n",
    "                    'val_loss':val_loss,\n",
    "                    'train_acc': train_acc,\n",
    "                    'val_acc': val_acc\n",
    "                })\n",
    "            \n",
    "        if self.logger:\n",
    "            self.logger.finish()\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:3llkptcy) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 36611... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14890239bb4d4f4c8450e11e6c31e70b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "</div><div class=\"wandb-col\">\n",
       "</div></div>\n",
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">4-layer|tanh</strong>: <a href=\"https://wandb.ai/fk280/SMAI-A3-double-mnist-ANN/runs/3llkptcy\" target=\"_blank\">https://wandb.ai/fk280/SMAI-A3-double-mnist-ANN/runs/3llkptcy</a><br/>\n",
       "Find logs at: <code>./wandb/run-20231026_191407-3llkptcy/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:3llkptcy). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.15.12 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/fk280/SMAI-A3-double-mnist-ANN/runs/39ylp9yc\" target=\"_blank\">4-layer|tanh</a></strong> to <a href=\"https://wandb.ai/fk280/SMAI-A3-double-mnist-ANN\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "params = {\n",
    "    'lr' : 1e-3,\n",
    "    'batch_size':512,\n",
    "    'epoch': 1000,\n",
    "}\n",
    "\n",
    "\n",
    "wandb.init(\n",
    "    project=\"SMAI-A3-double-mnist-ANN\",\n",
    "    config=params,\n",
    "    name=f\"4-layer|tanh\"\n",
    "    \n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model = MlpModel(),\n",
    "    train_loader = train_loader,\n",
    "    val_loader = val_loader, \n",
    "    device = device, \n",
    "    loss_fxn = nn.BCEWithLogitsLoss(),\n",
    "    logger=None,\n",
    "    params = params\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38f2b21a7a864822bb319591e17ede1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c78e844832aa4fe9bffc12327dbc3f0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/282 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5aeab3ed4c54e2fa649471b866de07e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/36 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch: 0] Training:[loss:0.4650 acc:0.001] Val:[loss:0.4043 acc:0.004]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40c6feb1920d48cfad79b9c7817fb646",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/282 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "186a0252d9564233bb847e63dd74d547",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/36 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch: 1] Training:[loss:0.3691 acc:0.019] Val:[loss:0.3435 acc:0.040]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ab8efe0ba39406d81c514a59d9d9651",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/282 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "113d93f93c1a47b99223823696f2137b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/36 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch: 2] Training:[loss:0.3214 acc:0.073] Val:[loss:0.3140 acc:0.088]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3119e443f4934550b4a846ae9e8ad7ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/282 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e04fc35057f4c34bbbc27ca10e1feb2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/36 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch: 3] Training:[loss:0.2871 acc:0.137] Val:[loss:0.2869 acc:0.157]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ff9cf03a16242dba4e00d6a72496a44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/282 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81f7b323da1f44ac8b2196762ecbe7c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/36 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch: 4] Training:[loss:0.2577 acc:0.215] Val:[loss:0.2649 acc:0.228]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a2a8c6635994060a69e89e43b37fa4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/282 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/SCARP/lib/python3.8/site-packages/PIL/Image.py:445\u001b[0m, in \u001b[0;36m_getencoder\u001b[0;34m(mode, encoder_name, args, extra)\u001b[0m\n\u001b[1;32m    444\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 445\u001b[0m     encoder \u001b[39m=\u001b[39m ENCODERS[encoder_name]\n\u001b[1;32m    446\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m:\n",
      "\u001b[0;31mKeyError\u001b[0m: 'raw'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home2/md.faizal/assignment-3-FaizalKarim280280/doubleMnist.ipynb Cell 11\u001b[0m line \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Blocalhost/home2/md.faizal/assignment-3-FaizalKarim280280/doubleMnist.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m trainer\u001b[39m.\u001b[39;49mtrain()\n",
      "\u001b[1;32m/home2/md.faizal/assignment-3-FaizalKarim280280/doubleMnist.ipynb Cell 11\u001b[0m line \u001b[0;36mTrainer.train\u001b[0;34m(self, epochs)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Blocalhost/home2/md.faizal/assignment-3-FaizalKarim280280/doubleMnist.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=52'>53</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtrain\u001b[39m(\u001b[39mself\u001b[39m, epochs \u001b[39m=\u001b[39m \u001b[39m10\u001b[39m):\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Blocalhost/home2/md.faizal/assignment-3-FaizalKarim280280/doubleMnist.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=53'>54</a>\u001b[0m     \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m tqdm(\u001b[39mrange\u001b[39m(epochs)):\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Blocalhost/home2/md.faizal/assignment-3-FaizalKarim280280/doubleMnist.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=55'>56</a>\u001b[0m         train_loss, train_acc \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgo_over_one_batch(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_loader, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtraining_step)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Blocalhost/home2/md.faizal/assignment-3-FaizalKarim280280/doubleMnist.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=56'>57</a>\u001b[0m         val_loss, val_acc \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgo_over_one_batch(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mval_loader, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mval_step)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Blocalhost/home2/md.faizal/assignment-3-FaizalKarim280280/doubleMnist.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=58'>59</a>\u001b[0m         \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m[Epoch: \u001b[39m\u001b[39m{\u001b[39;00mepoch\u001b[39m}\u001b[39;00m\u001b[39m] Training:[loss:\u001b[39m\u001b[39m{\u001b[39;00mtrain_loss\u001b[39m:\u001b[39;00m\u001b[39m.4f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m acc:\u001b[39m\u001b[39m{\u001b[39;00mtrain_acc\u001b[39m:\u001b[39;00m\u001b[39m.3f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m] Val:[loss:\u001b[39m\u001b[39m{\u001b[39;00mval_loss\u001b[39m:\u001b[39;00m\u001b[39m.4f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m acc:\u001b[39m\u001b[39m{\u001b[39;00mval_acc\u001b[39m:\u001b[39;00m\u001b[39m.3f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m]\u001b[39m\u001b[39m\"\u001b[39m )\n",
      "\u001b[1;32m/home2/md.faizal/assignment-3-FaizalKarim280280/doubleMnist.ipynb Cell 11\u001b[0m line \u001b[0;36mTrainer.go_over_one_batch\u001b[0;34m(self, loader, step_fxn)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Blocalhost/home2/md.faizal/assignment-3-FaizalKarim280280/doubleMnist.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=43'>44</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mgo_over_one_batch\u001b[39m(\u001b[39mself\u001b[39m, loader, step_fxn):\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Blocalhost/home2/md.faizal/assignment-3-FaizalKarim280280/doubleMnist.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=44'>45</a>\u001b[0m     loss, acc \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m, \u001b[39m0\u001b[39m\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Blocalhost/home2/md.faizal/assignment-3-FaizalKarim280280/doubleMnist.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=45'>46</a>\u001b[0m     \u001b[39mfor\u001b[39;00m x, y \u001b[39min\u001b[39;00m tqdm(loader):\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Blocalhost/home2/md.faizal/assignment-3-FaizalKarim280280/doubleMnist.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=46'>47</a>\u001b[0m         x, y \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39mto(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice), y\u001b[39m.\u001b[39mto(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Blocalhost/home2/md.faizal/assignment-3-FaizalKarim280280/doubleMnist.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=47'>48</a>\u001b[0m         l, a \u001b[39m=\u001b[39m step_fxn(x, y)\n",
      "File \u001b[0;32m~/miniconda3/envs/SCARP/lib/python3.8/site-packages/tqdm/notebook.py:257\u001b[0m, in \u001b[0;36mtqdm_notebook.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    255\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__iter__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    256\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 257\u001b[0m         \u001b[39mfor\u001b[39;00m obj \u001b[39min\u001b[39;00m \u001b[39msuper\u001b[39m(tqdm_notebook, \u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__iter__\u001b[39m():\n\u001b[1;32m    258\u001b[0m             \u001b[39m# return super(tqdm...) will not catch exception\u001b[39;00m\n\u001b[1;32m    259\u001b[0m             \u001b[39myield\u001b[39;00m obj\n\u001b[1;32m    260\u001b[0m     \u001b[39m# NB: except ... [ as ...] breaks IPython async KeyboardInterrupt\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/SCARP/lib/python3.8/site-packages/tqdm/std.py:1180\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1177\u001b[0m time \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_time\n\u001b[1;32m   1179\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1180\u001b[0m     \u001b[39mfor\u001b[39;00m obj \u001b[39min\u001b[39;00m iterable:\n\u001b[1;32m   1181\u001b[0m         \u001b[39myield\u001b[39;00m obj\n\u001b[1;32m   1182\u001b[0m         \u001b[39m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[1;32m   1183\u001b[0m         \u001b[39m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/SCARP/lib/python3.8/site-packages/torch/utils/data/dataloader.py:435\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    433\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    434\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()\n\u001b[0;32m--> 435\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    436\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    437\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    438\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    439\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/miniconda3/envs/SCARP/lib/python3.8/site-packages/torch/utils/data/dataloader.py:475\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    473\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    474\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 475\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    476\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[1;32m    477\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data)\n",
      "File \u001b[0;32m~/miniconda3/envs/SCARP/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py:44\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfetch\u001b[39m(\u001b[39mself\u001b[39m, possibly_batched_index):\n\u001b[1;32m     43\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mauto_collation:\n\u001b[0;32m---> 44\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     45\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     46\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/miniconda3/envs/SCARP/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py:44\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfetch\u001b[39m(\u001b[39mself\u001b[39m, possibly_batched_index):\n\u001b[1;32m     43\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mauto_collation:\n\u001b[0;32m---> 44\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     45\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     46\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "\u001b[1;32m/home2/md.faizal/assignment-3-FaizalKarim280280/doubleMnist.ipynb Cell 11\u001b[0m line \u001b[0;36mMultiDigitDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Blocalhost/home2/md.faizal/assignment-3-FaizalKarim280280/doubleMnist.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=20'>21</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__getitem__\u001b[39m(\u001b[39mself\u001b[39m, idx):\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Blocalhost/home2/md.faizal/assignment-3-FaizalKarim280280/doubleMnist.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=21'>22</a>\u001b[0m     x \u001b[39m=\u001b[39m load_image(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdf\u001b[39m.\u001b[39;49miloc[idx, \u001b[39m0\u001b[39;49m])\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Blocalhost/home2/md.faizal/assignment-3-FaizalKarim280280/doubleMnist.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=22'>23</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransform:\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Blocalhost/home2/md.faizal/assignment-3-FaizalKarim280280/doubleMnist.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=23'>24</a>\u001b[0m         x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransform(x)\n",
      "\u001b[1;32m/home2/md.faizal/assignment-3-FaizalKarim280280/doubleMnist.ipynb Cell 11\u001b[0m line \u001b[0;36mload_image\u001b[0;34m(file)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Blocalhost/home2/md.faizal/assignment-3-FaizalKarim280280/doubleMnist.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mload_image\u001b[39m(file):\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Blocalhost/home2/md.faizal/assignment-3-FaizalKarim280280/doubleMnist.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m     img \u001b[39m=\u001b[39m plt\u001b[39m.\u001b[39;49mimread(file)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Blocalhost/home2/md.faizal/assignment-3-FaizalKarim280280/doubleMnist.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m     img \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mresize(img, (\u001b[39m32\u001b[39m, \u001b[39m32\u001b[39m))\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Blocalhost/home2/md.faizal/assignment-3-FaizalKarim280280/doubleMnist.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m img\n",
      "File \u001b[0;32m~/miniconda3/envs/SCARP/lib/python3.8/site-packages/matplotlib/pyplot.py:2139\u001b[0m, in \u001b[0;36mimread\u001b[0;34m(fname, format)\u001b[0m\n\u001b[1;32m   2137\u001b[0m \u001b[39m@_copy_docstring_and_deprecators\u001b[39m(matplotlib\u001b[39m.\u001b[39mimage\u001b[39m.\u001b[39mimread)\n\u001b[1;32m   2138\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mimread\u001b[39m(fname, \u001b[39mformat\u001b[39m\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m-> 2139\u001b[0m     \u001b[39mreturn\u001b[39;00m matplotlib\u001b[39m.\u001b[39;49mimage\u001b[39m.\u001b[39;49mimread(fname, \u001b[39mformat\u001b[39;49m)\n",
      "File \u001b[0;32m~/miniconda3/envs/SCARP/lib/python3.8/site-packages/matplotlib/image.py:1561\u001b[0m, in \u001b[0;36mimread\u001b[0;34m(fname, format)\u001b[0m\n\u001b[1;32m   1559\u001b[0m             \u001b[39mreturn\u001b[39;00m imread(response, \u001b[39mformat\u001b[39m\u001b[39m=\u001b[39mext)\n\u001b[1;32m   1560\u001b[0m \u001b[39mwith\u001b[39;00m img_open(fname) \u001b[39mas\u001b[39;00m image:\n\u001b[0;32m-> 1561\u001b[0m     \u001b[39mreturn\u001b[39;00m (_pil_png_to_float_array(image)\n\u001b[1;32m   1562\u001b[0m             \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(image, PIL\u001b[39m.\u001b[39mPngImagePlugin\u001b[39m.\u001b[39mPngImageFile) \u001b[39melse\u001b[39;00m\n\u001b[1;32m   1563\u001b[0m             pil_to_array(image))\n",
      "File \u001b[0;32m~/miniconda3/envs/SCARP/lib/python3.8/site-packages/matplotlib/image.py:1729\u001b[0m, in \u001b[0;36m_pil_png_to_float_array\u001b[0;34m(pil_png)\u001b[0m\n\u001b[1;32m   1727\u001b[0m     \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39mdivide(pil_png, \u001b[39m2\u001b[39m\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39m4\u001b[39m \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m, dtype\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mfloat32)\n\u001b[1;32m   1728\u001b[0m \u001b[39mif\u001b[39;00m rawmode \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mL\u001b[39m\u001b[39m\"\u001b[39m:  \u001b[39m# Grayscale.\u001b[39;00m\n\u001b[0;32m-> 1729\u001b[0m     \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39;49mdivide(pil_png, \u001b[39m2\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39m8\u001b[39;49m \u001b[39m-\u001b[39;49m \u001b[39m1\u001b[39;49m, dtype\u001b[39m=\u001b[39;49mnp\u001b[39m.\u001b[39;49mfloat32)\n\u001b[1;32m   1730\u001b[0m \u001b[39mif\u001b[39;00m rawmode \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mI;16B\u001b[39m\u001b[39m\"\u001b[39m:  \u001b[39m# Grayscale.\u001b[39;00m\n\u001b[1;32m   1731\u001b[0m     \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39mdivide(pil_png, \u001b[39m2\u001b[39m\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39m16\u001b[39m \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m, dtype\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mfloat32)\n",
      "File \u001b[0;32m~/miniconda3/envs/SCARP/lib/python3.8/site-packages/PIL/Image.py:698\u001b[0m, in \u001b[0;36mImage.__array__\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m    696\u001b[0m     new[\u001b[39m\"\u001b[39m\u001b[39mdata\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtobytes(\u001b[39m\"\u001b[39m\u001b[39mraw\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mL\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    697\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 698\u001b[0m     new[\u001b[39m\"\u001b[39m\u001b[39mdata\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtobytes()\n\u001b[1;32m    700\u001b[0m \u001b[39mclass\u001b[39;00m \u001b[39mArrayData\u001b[39;00m:\n\u001b[1;32m    701\u001b[0m     __array_interface__ \u001b[39m=\u001b[39m new\n",
      "File \u001b[0;32m~/miniconda3/envs/SCARP/lib/python3.8/site-packages/PIL/Image.py:747\u001b[0m, in \u001b[0;36mImage.tobytes\u001b[0;34m(self, encoder_name, *args)\u001b[0m\n\u001b[1;32m    744\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mload()\n\u001b[1;32m    746\u001b[0m \u001b[39m# unpack data\u001b[39;00m\n\u001b[0;32m--> 747\u001b[0m e \u001b[39m=\u001b[39m _getencoder(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmode, encoder_name, args)\n\u001b[1;32m    748\u001b[0m e\u001b[39m.\u001b[39msetimage(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mim)\n\u001b[1;32m    750\u001b[0m bufsize \u001b[39m=\u001b[39m \u001b[39mmax\u001b[39m(\u001b[39m65536\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msize[\u001b[39m0\u001b[39m] \u001b[39m*\u001b[39m \u001b[39m4\u001b[39m)  \u001b[39m# see RawEncode.c\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/SCARP/lib/python3.8/site-packages/PIL/Image.py:446\u001b[0m, in \u001b[0;36m_getencoder\u001b[0;34m(mode, encoder_name, args, extra)\u001b[0m\n\u001b[1;32m    444\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    445\u001b[0m     encoder \u001b[39m=\u001b[39m ENCODERS[encoder_name]\n\u001b[0;32m--> 446\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;49;00m:\n\u001b[1;32m    447\u001b[0m     \u001b[39mpass\u001b[39;00m\n\u001b[1;32m    448\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02051130703d47498a197b563a1c3373",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/36 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.4232204861111111"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def test_model(model, loader):\n",
    "    acc = 0\n",
    "    for x, y in tqdm(loader):\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        with torch.no_grad():\n",
    "            y_pred = model(x)\n",
    "            y_pred_bin = (y_pred > 0.5).to(torch.int64)\n",
    "            acc += accuracy_score(y_pred_bin.cpu(), y.cpu())\n",
    "        \n",
    "    return acc/len(loader)\n",
    "\n",
    "test_model(trainer.model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNModel(nn.Module):\n",
    "    def __init__(self, params):\n",
    "        super().__init__()\n",
    "        self.params = params\n",
    "                \n",
    "        self.layers = nn.ModuleList(\n",
    "            [\n",
    "                self.get_block(1, 32, kernel_size=self.params['kernel_size'], padding=self.params['padding']), # 32, 16, 16\n",
    "                self.get_block(32, 64, kernel_size=self.params['kernel_size'], padding=self.params['padding']), # 64, 8, 8 \n",
    "                self.get_block(64, 128, kernel_size=self.params['kernel_size'], padding=self.params['padding']), # 128, 4, 4\n",
    "                self.get_block(128, 256, kernel_size=self.params['kernel_size'], padding=self.params['padding']), # 256, 2, 2\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "        self.fc1 = nn.Linear(256 * 2 * 2, 256 * 1 * 1)\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.fc3 = nn.Linear(128, 10)\n",
    "        self.drop = nn.Dropout(0.2)\n",
    "        \n",
    "    def get_block(self, in_c, out_c, kernel_size, padding):\n",
    "        return nn.Sequential(\n",
    "            nn.Conv2d(in_c, in_c, kernel_size=kernel_size, stride=1, padding=padding, bias=not self.params['batchnorm']),\n",
    "            nn.BatchNorm2d(in_c) if self.params['batchnorm'] else nn.Identity(),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            nn.Conv2d(in_c, out_c, 3, 1, 1, bias=True),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            nn.Conv2d(out_c, out_c, 3, 1, 1, bias=not self.params['batchnorm']),\n",
    "            nn.BatchNorm2d(out_c) if self.params['batchnorm'] else nn.Identity(),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Dropout(0.2) if self.params['dropout'] else nn.Identity()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "            \n",
    "        x = x.view(-1, 256*2*2)\n",
    "        x = self.drop(nn.LeakyReLU()(self.fc1(x)))\n",
    "        x = self.drop(nn.LeakyReLU()(self.fc2(x)))\n",
    "        return self.fc3(x)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured (use `wandb login --relogin` to force relogin)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.15.12 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/fk280/SMAI-A3-double-mnist-CNN/runs/3bqjov80\" target=\"_blank\">batch_size=1024</a></strong> to <a href=\"https://wandb.ai/fk280/SMAI-A3-double-mnist-CNN\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1ba734fe01a4730ac7ac70c28a35cd0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b71d3120d860416d9c2ca4da1772924d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/71 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e3201b3ba2e4adba7ea1abad81e7da6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch: 0] Training:[loss:0.4469 acc:0.004] Val:[loss:0.3617 acc:0.020]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ac34c8c8fa6416e83b58e688cda586a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/71 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2c81624b6684e4995c00189c2cd7c40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch: 1] Training:[loss:0.2781 acc:0.155] Val:[loss:0.1628 acc:0.446]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a01d417b11e4ea58117a7d0bc92cbfa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/71 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b76a173171046c79d2a763a6d42175e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch: 2] Training:[loss:0.0904 acc:0.749] Val:[loss:0.0523 acc:0.889]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da3f4f91e770415ea0e1ad672016f907",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/71 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99ab129d219b4e8eb0c5a67318581bcf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch: 3] Training:[loss:0.0412 acc:0.912] Val:[loss:0.0349 acc:0.929]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0468efc3f2644528f47da4ea3a98e44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/71 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c05565072747406380228f5a70e13d12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch: 4] Training:[loss:0.0293 acc:0.940] Val:[loss:0.0279 acc:0.945]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99136518927b4a1a95ead2faeb38e87b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/71 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abbf4c3a287140258f3c5e04413210e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch: 5] Training:[loss:0.0234 acc:0.953] Val:[loss:0.0241 acc:0.950]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9441c7c0b29420790abf3db7b7ee2a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/71 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4393169f64e4e6094ccee34e4eb7722",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch: 6] Training:[loss:0.0202 acc:0.960] Val:[loss:0.0211 acc:0.961]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31d93ba5fc634034a196d7f3cc438d8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/71 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "284f74823dee40b795c1cc0bfc7dae40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch: 7] Training:[loss:0.0176 acc:0.965] Val:[loss:0.0189 acc:0.966]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "692bc05d9dd848e5850967d4e51d5207",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/71 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "389c367a527640a69d8855887385aec0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch: 8] Training:[loss:0.0157 acc:0.970] Val:[loss:0.0188 acc:0.966]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1eef7253f7264cf891926a9874a09299",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/71 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3271fa3044045d18916aa21f371e48b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch: 9] Training:[loss:0.0145 acc:0.972] Val:[loss:0.0152 acc:0.972]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 26727... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "521c1e22dcf941fab10b10444a95e3d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train_acc</td><td>▁▂▆███████</td></tr><tr><td>train_loss</td><td>█▅▂▁▁▁▁▁▁▁</td></tr><tr><td>val_acc</td><td>▁▄▇███████</td></tr><tr><td>val_loss</td><td>█▄▂▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train_acc</td><td>0.97201</td></tr><tr><td>train_loss</td><td>0.0145</td></tr><tr><td>val_acc</td><td>0.97174</td></tr><tr><td>val_loss</td><td>0.01522</td></tr></table>\n",
       "</div></div>\n",
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">batch_size=1024</strong>: <a href=\"https://wandb.ai/fk280/SMAI-A3-double-mnist-CNN/runs/3bqjov80\" target=\"_blank\">https://wandb.ai/fk280/SMAI-A3-double-mnist-CNN/runs/3bqjov80</a><br/>\n",
       "Find logs at: <code>./wandb/run-20231026_181647-3bqjov80/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "params = {\n",
    "    'lr' : 7e-4,\n",
    "    'batch_size':256,\n",
    "    'epoch': 10,\n",
    "    'dropout': True,\n",
    "    'batchnorm': True,\n",
    "    'kernel_size': 3,\n",
    "    'padding': 1\n",
    "}\n",
    "\n",
    "\n",
    "wandb.init(\n",
    "    project=\"SMAI-A3-double-mnist-CNN\",\n",
    "    config=params,\n",
    "    name=f\"batch_size={256}\"\n",
    "    \n",
    ")\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=params['batch_size'], shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=params['batch_size'], shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=params['batch_size'], shuffle=False)\n",
    "\n",
    "\n",
    "trainer = Trainer(\n",
    "    model = CNNModel(params),\n",
    "    train_loader = train_loader,\n",
    "    val_loader = val_loader, \n",
    "    device = device, \n",
    "    loss_fxn = nn.BCEWithLogitsLoss(),\n",
    "    logger=None,\n",
    "    params=params\n",
    ")\n",
    "\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SCARP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
